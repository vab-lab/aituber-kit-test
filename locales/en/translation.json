{
  "Settings": "■ Settings",
  "AISettings": "■ AI Settings",
  "YoutubeSettings": "■ YouTube Settings",
  "VoiceSettings": "■ Voice Settings",
  "SlideSettings": "■ Slide Settings",
  "OtherSettings": "■ Other",
  "ExternalLinkageMode": "External Linkage Mode (WebSocket)",
  "YoutubeMode": "YouTube Mode",
  "YoutubeInfo": "The first character of the comment is '#', it is ignored.",
  "YoutubeAPIKey": "YouTube API Key",
  "YoutubeLiveID": "YouTube Live ID",
  "ConversationContinuityMode": "Conversation Continuity Mode (Beta)",
  "ConversationContinuityModeInfo": "When there is no comment, AI tries to continue the conversation. Currently only OpenAI, Anthropic Claude, Google Gemini are supported.",
  "ConversationContinuityModeInfo2": "One answer calls LLM multiple times, so API usage may increase. Please be aware of this.",
  "ConversationContinuityModeInfo3": "gpt-4o, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet work relatively stably.",
  "StatusOn": "Status: ON",
  "StatusOff": "Status: OFF",
  "Select": "Select",
  "TestVoice": "Test Voice",
  "SelectAIService": "Select AI Service",
  "LocalLLM": "Local LLM",
  "SelectModel": "Select Model",
  "OpenAIAPIKeyLabel": "OpenAI API Key",
  "AnthropicAPIKeyLabel": "Anthropic API Key",
  "GoogleAPIKeyLabel": "Google Gemini API Key",
  "AzureAPIKeyLabel": "Azure OpenAI API Key",
  "AzureAPIURL": "Azure OpenAI API URL",
  "GroqAPIKeyLabel": "Groq API Key",
  "CohereAPIKeyLabel": "Cohere API Key",
  "MistralAIAPIKeyLabel": "MistralAI API Key",
  "PerplexityAPIKeyLabel": "Perplexity API Key",
  "FireworksAPIKeyLabel": "Fireworks API Key",
  "DifyAPIKeyLabel": "Dify API Key",
  "APIKeyInstruction": "You can obtain the API key below. Enter the obtained API key into the form.",
  "LocalLLMInfo": "Local LLM server must be running. Setup is as follows.",
  "LocalLLMInfo2": "Please enter the URL of the local LLM server (including port number) and the model name.",
  "GroqInfo": "Groq API is accessed directly from the browser.",
  "DifyInfo": "Dify only supports chatbot and agent type.",
  "DifyInfo2": "The length of the conversation history is dependent on the specifications of Dify.",
  "DifyInfo3": "Example: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "If you are using Dify, the system prompt will not be used. Please set Dify chatbot.",
  "EnterURL": "URL",
  "CharacterModelLabel": "Character Model",
  "CharacterModelInfo": "The model may take time to load when first displayed.",
  "OpenVRM": "Open VRM",
  "BackgroundImage": "Background Image",
  "ChangeBackgroundImage": "Change Background Image",
  "CharacterSettingsPrompt": "Character Settings (System Prompt)",
  "CharacterSettingsReset": "Reset Character Settings",
  "SyntheticVoiceEngineChoice": "Choose Synthetic Voice Engine",
  "VoiceAdjustment": "Voice Adjustment",
  "VoiceEngineInstruction": "Select the synthetic voice engine you want to use.",
  "UsingKoeiromap": "Koeiromap",
  "KoeiromapInfo": "Using Koeiromap API from Koemotion. It only supports Japanese. For more details, please refer to the link below.",
  "UsingVoiceVox": "VOICEVOX",
  "VoiceVoxInfo": "Using VOICEVOX. It only supports Japanese. It uses a local API, you need to download and launch the app that suits your environment from the site below.",
  "VoicevoxSpeed": "Speed",
  "VoicevoxPitch": "Pitch",
  "VoicevoxIntonation": "Intonation",
  "UsingAivisSpeech": "AivisSpeech",
  "AivisSpeechInfo": "Using AivisSpeech. It only supports Japanese. It uses a local API, you need to download and launch the app that suits your environment from the site below.",
  "AivisSpeechSpeaker": "Speaker",
  "AivisSpeechSpeed": "Speed",
  "AivisSpeechPitch": "Pitch",
  "AivisSpeechIntonation": "Intonation",
  "UsingNijiVoice": "NijiVoice",
  "NijiVoiceInfo": "NijiVoice API is used. It supports only Japanese. API key can be obtained from the URL below.",
  "NijiVoiceApiKey": "NijiVoice API Key",
  "NijiVoiceActorId": "NijiVoice Actor ID",
  "NijiVoiceSpeed": "NijiVoice Speed",
  "UpdateSpeakerList": "Update Speaker List",
  "UsingGoogleTTS": "Google TTS",
  "UsingStyleBertVITS2": "Style-Bert-VITS2",
  "StyleBertVITS2Info": "Using Style-Bert-VITS2. It supports only Japanese, English, and Chinese. If using a local API, you need to download and launch the app that suits your environment from the site below. Please also set up an API key if necessary.",
  "SpeakerSelection": "Speaker Selection",
  "IncludeTimestampInUserMessage": "Include timestamp in user message",
  "IncludeTimestampInUserMessageInfo": "Including a timestamp in user messages allows AI to generate responses considering time. Please include the following text in the system prompt.\n\n「The user input may be requested with a timestamp. This represents the time at the request, so please generate a response considering that time.」",
  "GoogleTTSInfo": "Using Google Cloud Text-to-Speech. It supports multiple languages.",
  "AuthFileInstruction": "Obtain the authentication JSON file below and place it in the root folder of the repository as 'credentials.json'.",
  "LanguageModelURL": "Select the language model from the URL below.",
  "LanguageChoice": "Language Choice",
  "StyleBeatVITS2ServerURL": "Server URL",
  "StyleBeatVITS2ApiKey": "API Key",
  "StyleBeatVITS2ModelID": "Model ID",
  "StyleBeatVITS2Style": "Style",
  "StyleBeatVITS2SdpRatio": "SDP/DP Mixing Ratio",
  "StyleBeatVITS2Length": "Speech Rate",
  "ConversationHistory": "Conversation History",
  "ConversationHistoryInfo": "The latest 10 conversation texts are stored as memories.",
  "ConversationHistoryReset": "Reset Conversation History",
  "NotConnectedToExternalAssistant": "Not connected to an external assistant.",
  "APIKeyNotEntered": "API key is not entered.",
  "ChatLog": "Conversation Log",
  "EnterYourQuestion": "Enter your question here",
  "AnswerGenerating": "Answer Generating",
  "AboutThisApplication": "About This Application",
  "AboutThisApplicationDescription": "Enjoy conversations with a 3D character right in your web browser, using microphone or text input and voice synthesis. You can also change the character (VRM), adjust its personality, and modify its voice.<br />Settings can be changed from the menu button in the top left.",
  "TechnologyIntroduction": "Technology Introduction",
  "TechnologyIntroductionDescription1": "This app was created by modifying pixiv's <b>ChatVRM</b>. The original source code can be found",
  "TechnologyIntroductionLink1": "here",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "For displaying and manipulating 3D models,",
  "TechnologyIntroductionDescription4": "is used. For generating conversation text, various LLMs such as",
  "TechnologyIntroductionDescription5": "are used. For speech synthesis, various TTS engines like",
  "TechnologyIntroductionDescription6": "are utilized. For more details, please check out this",
  "TechnologyIntroductionLink2": "explanatory article",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "The source code for this app is publicly available on GitHub. Feel free to modify and adapt it as you like.",
  "SourceCodeDescription2": "For commercial use, please refer to the README of the same repository.",
  "RepositoryURL": "Repository URL:",
  "DontShowIntroductionNextTime": "Do not show this dialog next time",
  "Close": "CLOSE",
  "Language": "Language",
  "UsingGSVITTS": "GSVI TTS",
  "GSVITTSInfo": "GSVI TTS Settings",
  "GSVITTSServerUrl": "GSVI TTS Endpoint API",
  "GSVITTSModelID": "GSVI TTS Model ID",
  "GSVITTSBatchSize": "GSVI TTS Batch Size (1 ~ 100 The larger the value, the faster the inference speed, but it might exhaust memory if too large.)",
  "GSVITTSSpeechRate": "Speech Rate (0.5 ~ 2.0 The bigger the value, the faster it is.)",
  "UsingElevenLabs": "ElevenLabs",
  "ElevenLabsInfo": "ElevenLabs API is used. It supports multiple languages. API key can be obtained from the URL below.",
  "ElevenLabsApiKey": "ElevenLabs API Key",
  "ElevenLabsVoiceId": "ElevenLabs Voice ID",
  "ElevenLabsVoiceIdInfo": "Voice ID can be selected from the URL below.",
  "CharacterName": "Character name",
  "ShowAssistantText": "Show answer box",
  "ShowCharacterName": "Show character name in the answer box",
  "ShowControlPanel": "Show settings button",
  "ShowControlPanelInfo": "The settings screen can be displayed by pressing Cmd + . (Mac) / Ctrl + . (Windows) .",
  "SlideMode": "Slide Mode",
  "SelectedSlideDocs": "Selected Slide Documents",
  "SlideModeDescription": "This is a mode where AI automatically presents slides. It is only available when the selected AI service is OpenAI, Anthropic Claude, or Google Gemini.",
  "PdfConvertLabel": "PDF Slide Conversion",
  "PdfConvertDescription": "Convert PDF to slide mode data. Available only when the selected AI service is OpenAI, Anthropic Claude, or Google Gemini.",
  "PdfConvertFileUpload": "Select PDF file",
  "PdfConvertFolderName": "Save folder name",
  "PdfConvertModelSelect": "Select model",
  "PdfConvertButton": "Convert PDF to slides",
  "PdfConvertLoading": "Converting...",
  "PdfConvertSuccess": "Conversion completed",
  "PdfConvertError": "Conversion failed",
  "PdfConvertSubmitError": "Please make sure the PDF file, folder name, and API key are set.",
  "LocalStorageReset": "Reset Settings",
  "LocalStorageResetInfo": "Environment variables are prioritized if set. The page will be reloaded.",
  "LocalStorageResetButton": "Reset Settings",
  "Errors": {
    "EmptyAPIKey": "API key is not set",
    "AIInvalidProperty": "AI service settings are incorrect",
    "AIAPIError": "An error occurred while executing the AI API",
    "InvalidAIService": "The selected AI service is not valid",
    "MethodNotAllowed": "The request is not appropriate",
    "TTSServiceError": "An error occurred in the {{serviceName}} TTS service: {{message}}",
    "UnexpectedError": "An unexpected error occurred",
    "LocalLLMError": "Local LLM error",
    "LocalLLMStreamError": "Local LLM stream error",
    "LocalLLMConnectionError": "Local LLM server connection error",
    "LocalLLMNotFound": "Local LLM endpoint not found",
    "LocalLLMAPIError": "Local LLM API error"
  },
  "MessageReceiver": "Receive instructions from outside",
  "MessageReceiverDescription": "You can use API to instruct AI characters to speak from outside.",
  "ClientID": "Client ID",
  "OpenSendMessagePage": "Open Send Message Page",
  "RealtimeAPIMode": "Realtime API Mode",
  "RealtimeAPIModeContentType": "Send Type",
  "RealtimeAPIModeVoice": "Voice Type",
  "AudioMode": "Audio Mode (Beta)",
  "InputText": "Text",
  "InputAudio": "Audio",
  "UpdateRealtimeAPISettings": "Update Realtime API Settings",
  "UpdateRealtimeAPISettingsInfo": "When updating the API key, Azure Endpoint, voice type, or system prompt, please press the update button to start a new WebSocket session.",
  "AzureEndpoint": "Azure Endpoint",
  "Toasts": {
    "WebSocketConnectionError": "Error occurred in WebSocket connection",
    "WebSocketConnectionClosed": "WebSocket connection closed",
    "WebSocketConnectionAttempt": "Attempting WebSocket connection...",
    "WebSocketConnectionSuccess": "WebSocket connection successful",
    "FunctionExecuting": "Executing {{funcName}}",
    "FunctionExecutionFailed": "Execution of {{funcName}} failed",
    "FirefoxNotSupported": "This feature is not supported on Firefox",
    "SpeechRecognitionError": "Speech recognition error occurred"
  },
  "UsingOpenAITTS": "Using OpenAI",
  "OpenAITTSInfo": "Using OpenAI. It supports multiple languages. If you select OpenAI as the AI service, you do not need to set the API key below.",
  "OpenAITTSVoice": "Voice type",
  "OpenAITTSModel": "Model",
  "OpenAITTSSpeed": "Speed",
  "UsingAzureTTS": "Using Azure OpenAI",
  "AzureTTSInfo": "Using Azure OpenAI. It supports multiple languages.",
  "SendMessage": {
    "title": "AITuberKit External Adapter",
    "directSendTitle": "Directly speak to AI character",
    "directSendDescription": "You can send the message directly to the AI character. If multiple messages are sent, they are processed in order. The voice model is the one selected in the AITuberKit settings.",
    "aiGenerateTitle": "Generate AI response and then speak",
    "aiGenerateDescription": "The AI generates a response from the message sent and then speaks it. If multiple messages are sent, they are processed in order. The AI model and voice model are the ones selected in the AITuberKit settings. The system prompt can be selected to use the AITuberKit system prompt or a custom system prompt. If you want to load the past conversation history, include the string [conversation_history] in the system prompt or user message.",
    "useCurrentSystemPrompt": "Use AITuberKit system prompt",
    "userInputTitle": "Send user input",
    "userInputDescription": "The message sent is processed the same as when input from the AITuberKit input form. If multiple messages are sent, they are processed in order. The AI model and voice model are the ones selected in the AITuberKit settings. The system prompt and conversation history are the values set in AITuberKit."
  }
}
